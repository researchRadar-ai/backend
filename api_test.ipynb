{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import pprint as pp\n",
    "pprint = pp.PrettyPrinter(indent=4).pprint\n",
    "import requests\n",
    "import pysondb\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      "<html lang=en>\n",
      "<title>405 Method Not Allowed</title>\n",
      "<h1>Method Not Allowed</h1>\n",
      "<p>The method is not allowed for the requested URL.</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"http://localhost:3000/api/project/list_papers\"\n",
    "headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "data = {\n",
    "    # 'type': \"saved\", # or toread\n",
    "    'type': \"toread\", # or toread\n",
    "    'project_id': 148702791823144807,\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.get(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "print(response.text)\n",
    "\n",
    "# add_project(\"robotaics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'abstract': 'Quantum computing allows for the potential of significant '\n",
      "                'advancements in\\n'\n",
      "                'both the speed and the capacity of widely used machine '\n",
      "                'learning techniques.\\n'\n",
      "                'Here we employ quantum algorithms for the Hopfield network, '\n",
      "                'which can be used\\n'\n",
      "                'for pattern recognition, reconstruction, and optimization as '\n",
      "                'a realization of a\\n'\n",
      "                'content-addressable memory system. We show that an '\n",
      "                'exponentially large network\\n'\n",
      "                'can be stored in a polynomial number of quantum bits by '\n",
      "                'encoding the network\\n'\n",
      "                'into the amplitudes of quantum states. By introducing a '\n",
      "                'classical technique for\\n'\n",
      "                'operating the Hopfield network, we can leverage quantum '\n",
      "                'algorithms to obtain a\\n'\n",
      "                'quantum computational complexity that is logarithmic in the '\n",
      "                'dimension of the\\n'\n",
      "                'data. We also present an application of our method as a '\n",
      "                'genetic sequence\\n'\n",
      "                'recognizer.',\n",
      "    'authors': [   'Patrick Rebentrost',\n",
      "                   'Thomas R. Bromley',\n",
      "                   'Christian Weedbrook',\n",
      "                   'Seth Lloyd'],\n",
      "    'citations': 125,\n",
      "    'paper_id': '1710.03599',\n",
      "    'title': 'Quantum Hopfield neural network',\n",
      "    'year': '2017'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_semantic_scholar_info(arxiv_id):\n",
    "    base_url = \"https://api.semanticscholar.org/v1/paper/arXiv:\"\n",
    "    \n",
    "    # Fetch data from Semantic Scholar\n",
    "    response = requests.get(base_url + arxiv_id)\n",
    "    data = response.json()\n",
    "\n",
    "    # Return citation count and impact score\n",
    "    # Note: Semantic Scholar doesn't have a generic \"impact score\", but citations can be a metric of impact.\n",
    "    return len(data.get(\"citations\", []))\n",
    "\n",
    "\n",
    "\n",
    "def get_paper_base_data(paper_id):\n",
    "    base_url = \"http://export.arxiv.org/api/query?\"\n",
    "    query = \"id_list=\" + paper_id\n",
    "    \n",
    "    # Send a GET request to the arXiv API\n",
    "    response = requests.get(base_url + query)\n",
    "    \n",
    "    # Raise an exception if the request was unsuccessful\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Parse the XML response\n",
    "    root = ET.fromstring(response.text)\n",
    "    \n",
    "    # Extract information from XML\n",
    "    ns = {'default': 'http://www.w3.org/2005/Atom'}\n",
    "    entry = root.find('default:entry', ns)\n",
    "    \n",
    "    title = entry.find('default:title', ns).text.strip()\n",
    "    authors = [author.find('default:name', ns).text for author in entry.findall('default:author', ns)]\n",
    "    abstract = entry.find('default:summary', ns).text.strip()\n",
    "    year = entry.find('default:published', ns).text.split('-')[0]\n",
    "    \n",
    "    # Return the extracted information in the desired format\n",
    "    return {\n",
    "        \"paper_id\": paper_id,\n",
    "        \"title\": title,\n",
    "        \"authors\": authors,\n",
    "        \"abstract\": abstract,\n",
    "        \"year\": year,\n",
    "        \"citations\": get_semantic_scholar_info(paper_id)\n",
    "    }\n",
    "\n",
    "# Test\n",
    "paper_id = \"1710.03599\"\n",
    "# paper_id = \"2101.12345\"\n",
    "pprint(get_paper_base_data(paper_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_in_project = {\n",
    "    \"paper_id\": \"1710.03599\",\n",
    "    \"project_id\": \"1234567890\",\n",
    "    \"rating\": 1,\n",
    "    \"annotations\": {},\n",
    "    \"engagement\": {\n",
    "        \"view_count\": 0,\n",
    "        \"view_duration\": 0,\n",
    "    },\n",
    "    \"saved\": True,\n",
    "    \"read\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_project(name):\n",
    "    project = {\n",
    "        \"name\": name,\n",
    "        \"papers\": [],\n",
    "        \"imgUrl\": \"/AI.jpeg\"\n",
    "    }\n",
    "    return projects.add(project) # returns id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_paper_to_project(project_id, paper_id):\n",
    "    project_paper = {\n",
    "        \"project_id\": project_id,\n",
    "        \"paper_id\": paper_id,\n",
    "        \"rating\": 1,\n",
    "        \"annotations\": {},\n",
    "        \"engagement\": {\n",
    "            \"click_count\": 0,\n",
    "            \"view_duration\": 0,\n",
    "        },\n",
    "        \"saved\": False,\n",
    "        \"read\": False\n",
    "    }\n",
    "    id = projPapers.add(project_paper)\n",
    "\n",
    "    old_papers = projects.getById(project_id)[\"papers\"]\n",
    "    old_papers.append(id)\n",
    "\n",
    "    projects.updateById(project_id, {\"papers\": old_papers})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_engagement(metric, value, project_id, paper_id):\n",
    "    db_paper_id = projPapers.getByQuery({\"paper_id\": paper_id, \"project_id\": project_id})[0][\"id\"]\n",
    "    \n",
    "    if metric == \"click\":\n",
    "        upd_engagement = projPapers.getById(db_paper_id)[\"engagement\"]\n",
    "        upd_engagement[\"click_count\"] += 1\n",
    "        projPapers.updateById(db_paper_id, {\"engagement\": upd_engagement})\n",
    "    elif metric == \"view\":\n",
    "        upd_engagement = projPapers.getById(db_paper_id)[\"engagement\"]\n",
    "        upd_engagement[\"view_duration\"] += value\n",
    "        projPapers.updateById(db_paper_id, {\"engagement\": upd_engagement})\n",
    "    elif metric == \"read\":\n",
    "        projPapers.updateById(db_paper_id, {\"read\": value})\n",
    "    elif metric == \"save\":\n",
    "        projPapers.updateById(db_paper_id, {\"saved\": value})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n"
     ]
    }
   ],
   "source": [
    "papers = pysondb.db.getDb(\"data/papers\")\n",
    "projects = pysondb.db.getDb(\"data/projects\")\n",
    "projPapers = pysondb.db.getDb(\"data/project_papers\")\n",
    "\n",
    "papers.deleteAll()\n",
    "projects.deleteAll()\n",
    "projPapers.deleteAll()\n",
    "\n",
    "# testing: this is intital data\n",
    "\n",
    "\n",
    "# add quantum\n",
    "project = {\n",
    "    \"name\": \"Quantum Physics\",\n",
    "    \"papers\": [],\n",
    "    \"imgUrl\": \"/QuantumPhysics.jpeg\"\n",
    "}\n",
    "qn_id = projects.add(project)\n",
    "\n",
    "\n",
    "paper_ids = ['1709.02779',\n",
    " '1611.09347',\n",
    " '1611.09347v2',\n",
    " '1708.09757',\n",
    " '1709.02779',\n",
    " '1707.08561v1',\n",
    " '1708.09757v1',\n",
    " '2208.08068',\n",
    " '1710.03599v1',\n",
    " '1908.04480v2']\n",
    "\n",
    "# proj_id = add_project(\"Sample Project\")\n",
    "\n",
    "for paper_id in paper_ids:\n",
    "    papers.add(get_paper_base_data(paper_id))\n",
    "    add_paper_to_project(qn_id, paper_id)\n",
    "\n",
    "    \n",
    "\n",
    "update_engagement(\"click\", 1, qn_id, paper_id)\n",
    "update_engagement(\"view\", 15, qn_id, paper_id)\n",
    "update_engagement(\"view\", 15, qn_id, paper_id)\n",
    "update_engagement(\"read\", True, qn_id, paper_id)\n",
    "update_engagement(\"save\", True, qn_id, paper_id)\n",
    "update_engagement(\"save\", True, qn_id, paper_ids[0])\n",
    "update_engagement(\"save\", True, qn_id, paper_ids[2])\n",
    "update_engagement(\"save\", True, qn_id, paper_ids[3])\n",
    "update_engagement(\"save\", True, qn_id, paper_ids[4])\n",
    "update_engagement(\"read\", True, qn_id, paper_ids[4])\n",
    "update_engagement(\"read\", True, qn_id, paper_ids[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'project_id': 148702791823144807,\n",
       "  'paper_id': '1709.02779',\n",
       "  'rating': 1,\n",
       "  'annotations': {},\n",
       "  'engagement': {'click_count': 0, 'view_duration': 0},\n",
       "  'saved': True,\n",
       "  'read': True,\n",
       "  'id': 178494889177972764},\n",
       " {'project_id': 148702791823144807,\n",
       "  'paper_id': '1611.09347',\n",
       "  'rating': 1,\n",
       "  'annotations': {},\n",
       "  'engagement': {'click_count': 0, 'view_duration': 0},\n",
       "  'saved': False,\n",
       "  'read': False,\n",
       "  'id': 239451734285630063},\n",
       " {'project_id': 148702791823144807,\n",
       "  'paper_id': '1611.09347v2',\n",
       "  'rating': 1,\n",
       "  'annotations': {},\n",
       "  'engagement': {'click_count': 0, 'view_duration': 0},\n",
       "  'saved': True,\n",
       "  'read': True,\n",
       "  'id': 754822796031261480},\n",
       " {'project_id': 148702791823144807,\n",
       "  'paper_id': '1708.09757',\n",
       "  'rating': 1,\n",
       "  'annotations': {},\n",
       "  'engagement': {'click_count': 0, 'view_duration': 0},\n",
       "  'saved': True,\n",
       "  'read': False,\n",
       "  'id': 207245952752736323},\n",
       " {'project_id': 148702791823144807,\n",
       "  'paper_id': '1709.02779',\n",
       "  'rating': 1,\n",
       "  'annotations': {},\n",
       "  'engagement': {'click_count': 0, 'view_duration': 0},\n",
       "  'saved': False,\n",
       "  'read': False,\n",
       "  'id': 321261517891845552},\n",
       " {'project_id': 148702791823144807,\n",
       "  'paper_id': '1707.08561v1',\n",
       "  'rating': 1,\n",
       "  'annotations': {},\n",
       "  'engagement': {'click_count': 0, 'view_duration': 0},\n",
       "  'saved': False,\n",
       "  'read': False,\n",
       "  'id': 221762369844121235},\n",
       " {'project_id': 148702791823144807,\n",
       "  'paper_id': '1708.09757v1',\n",
       "  'rating': 1,\n",
       "  'annotations': {},\n",
       "  'engagement': {'click_count': 0, 'view_duration': 0},\n",
       "  'saved': False,\n",
       "  'read': False,\n",
       "  'id': 301992180675760610},\n",
       " {'project_id': 148702791823144807,\n",
       "  'paper_id': '2208.08068',\n",
       "  'rating': 1,\n",
       "  'annotations': {},\n",
       "  'engagement': {'click_count': 0, 'view_duration': 0},\n",
       "  'saved': False,\n",
       "  'read': False,\n",
       "  'id': 128389792724135020},\n",
       " {'project_id': 148702791823144807,\n",
       "  'paper_id': '1710.03599v1',\n",
       "  'rating': 1,\n",
       "  'annotations': {},\n",
       "  'engagement': {'click_count': 0, 'view_duration': 0},\n",
       "  'saved': False,\n",
       "  'read': False,\n",
       "  'id': 165067520792241930},\n",
       " {'project_id': 148702791823144807,\n",
       "  'paper_id': '1908.04480v2',\n",
       "  'rating': 1,\n",
       "  'annotations': {},\n",
       "  'engagement': {'click_count': 1, 'view_duration': 30},\n",
       "  'saved': True,\n",
       "  'read': True,\n",
       "  'id': 236755119090511479}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projPapers.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'title': 'Opportunities and challenges for quantum-assisted machine learning in\\n  near-term quantum computers',\n",
       "  'authors': 'Alejandro Perdomo-Ortiz, Marcello Benedetti, John Realpe-Gómez, Rupak Biswas',\n",
       "  'abstract': 'With quantum computing technologies nearing the era of commercialization and\\nquantum supremacy, machine learning (ML) appears as one of the promising\\n\"killer\" applications. Despite significant effort, there has been a disconnect\\nbetween most quantum ML proposals, the needs of ML practitioners, and the\\ncapabilities of near-term quantum devices to demonstrate quantum enhancement in\\nthe near future. In this contribution to the focus collection on \"What would\\nyou do with 1000 qubits?\", we provide concrete examples of intractable ML tasks\\nthat could be enhanced with near-term devices. We argue that to reach this\\ntarget, the focus should be on areas where ML researchers are struggling, such\\nas generative models in unsupervised and semi-supervised learning, instead of\\nthe popular and more tractable supervised learning techniques. We also\\nhighlight the case of classical datasets with potential quantum-like\\nstatistical correlations where quantum models could be more suitable. We focus\\non hybrid quantum-classical approaches and illustrate some of the key\\nchallenges we foresee for near-term implementations. Finally, we introduce the\\nquantum-assisted Helmholtz machine (QAHM), an attempt to use near-term quantum\\ndevices to tackle high-dimensional datasets of continuous variables. Instead of\\nusing quantum computers to assist deep learning, as previous approaches do, the\\nQAHM uses deep learning to extract a low-dimensional binary representation of\\ndata, suitable for relatively small quantum processors which can assist the\\ntraining of an unsupervised generative model. Although we illustrate this\\nconcept on a quantum annealer, other quantum platforms could benefit as well\\nfrom this hybrid quantum-classical framework.',\n",
       "  'year': '2017',\n",
       "  'id': 884179599198170424,\n",
       "  'journal': 'bullshit'}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request = {\n",
    "    # 'type': \"saved\", # or toread\n",
    "    'type': \"toread\", # or toread\n",
    "    'project_id': 148702791823144807,\n",
    "}\n",
    "\n",
    "def list_papers():\n",
    "    proj_papers = projPapers.getByQuery({\"project_id\": request[\"project_id\"]})\n",
    "\n",
    "    if request[\"type\"] == \"saved\":\n",
    "        proj_papers = list(filter(lambda x: x[\"saved\"] == True & x[\"read\"] == True, proj_papers))\n",
    "    elif request[\"type\"] == \"toread\":\n",
    "        new = []\n",
    "        for paper in proj_papers:\n",
    "            if paper[\"saved\"] == True and paper[\"read\"] == False:\n",
    "                new.append(paper)\n",
    "        proj_papers = new\n",
    "\n",
    "\n",
    "    # reformat and get paper data\n",
    "    output = []\n",
    "\n",
    "    for paper in proj_papers:\n",
    "        paper_data = papers.getByQuery({\"paper_id\": paper[\"paper_id\"]})[0]\n",
    "        \n",
    "        del paper_data[\"paper_id\"]\n",
    "        del paper_data[\"citations\"]\n",
    "        paper_data[\"journal\"] = \"bullshit\"\n",
    "        paper_data[\"authors\"] = ', '.join(paper_data[\"authors\"])\n",
    "\n",
    "        print(paper['read'], paper['saved'])\n",
    "\n",
    "        output.append(paper_data)\n",
    "\n",
    "\n",
    "\n",
    "    return output\n",
    "\n",
    "list_papers()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
