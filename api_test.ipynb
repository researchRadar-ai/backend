{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import pprint as pp\n",
    "pprint = pp.PrettyPrinter(indent=4).pprint\n",
    "import requests\n",
    "import pysondb\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"abstract\": \"Quantum information technologies, and intelligent learning systems, are both\\nemergent technologies that will likely have a transforming impact on our\\nsociety. The respective underlying fields of research -- quantum information\\n(QI) versus machine learning (ML) and artificial intelligence (AI) -- have\\ntheir own specific challenges, which have hitherto been investigated largely\\nindependently. However, in a growing body of recent work, researchers have been\\nprobing the question to what extent these fields can learn and benefit from\\neach other. QML explores the interaction between quantum computing and ML,\\ninvestigating how results and techniques from one field can be used to solve\\nthe problems of the other. Recently, we have witnessed breakthroughs in both\\ndirections of influence. For instance, quantum computing is finding a vital\\napplication in providing speed-ups in ML, critical in our \\\"big data\\\" world.\\nConversely, ML already permeates cutting-edge technologies, and may become\\ninstrumental in advanced quantum technologies. Aside from quantum speed-up in\\ndata analysis, or classical ML optimization used in quantum experiments,\\nquantum enhancements have also been demonstrated for interactive learning,\\nhighlighting the potential of quantum-enhanced learning agents. Finally, works\\nexploring the use of AI for the very design of quantum experiments, and for\\nperforming parts of genuine research autonomously, have reported their first\\nsuccesses. Beyond the topics of mutual enhancement, researchers have also\\nbroached the fundamental issue of quantum generalizations of ML/AI concepts.\\nThis deals with questions of the very meaning of learning and intelligence in a\\nworld that is described by quantum mechanics. In this review, we describe the\\nmain ideas, recent developments, and progress in a broad spectrum of research\\ninvestigating machine learning and artificial intelligence in the quantum\\ndomain.\",\n",
      "    \"authors\": \"Vedran Dunjko, Hans J. Briegel\",\n",
      "    \"id\": 142334257173582698,\n",
      "    \"journal\": \"bullshit\",\n",
      "    \"title\": \"Machine learning \\\\& artificial intelligence in the quantum domain\",\n",
      "    \"year\": \"2017\"\n",
      "  },\n",
      "  {\n",
      "    \"abstract\": \"Fuelled by increasing computer power and algorithmic advances, machine\\nlearning techniques have become powerful tools for finding patterns in data.\\nSince quantum systems produce counter-intuitive patterns believed not to be\\nefficiently produced by classical systems, it is reasonable to postulate that\\nquantum computers may outperform classical computers on machine learning tasks.\\nThe field of quantum machine learning explores how to devise and implement\\nconcrete quantum software that offers such advantages. Recent work has made\\nclear that the hardware and software challenges are still considerable but has\\nalso opened paths towards solutions.\",\n",
      "    \"authors\": \"Jacob Biamonte, Peter Wittek, Nicola Pancotti, Patrick Rebentrost, Nathan Wiebe, Seth Lloyd\",\n",
      "    \"id\": 896041604086190531,\n",
      "    \"journal\": \"bullshit\",\n",
      "    \"title\": \"Quantum Machine Learning\",\n",
      "    \"year\": \"2016\"\n",
      "  },\n",
      "  {\n",
      "    \"abstract\": \"Recent work has shown that quantum annealing for machine learning, referred\\nto as QAML, can perform comparably to state-of-the-art machine learning methods\\nwith a specific application to Higgs boson classification. We propose QAML-Z, a\\nnovel algorithm that iteratively zooms in on a region of the energy surface by\\nmapping the problem to a continuous space and sequentially applying quantum\\nannealing to an augmented set of weak classifiers. Results on a programmable\\nquantum annealer show that QAML-Z matches classical deep neural network\\nperformance at small training set sizes and reduces the performance margin\\nbetween QAML and classical deep neural networks by almost 50% at large training\\nset sizes, as measured by area under the ROC curve. The significant improvement\\nof quantum annealing algorithms for machine learning and the use of a discrete\\nquantum algorithm on a continuous optimization problem both opens a new class\\nof problems that can be solved by quantum annealers and suggests the approach\\nin performance of near-term quantum machine learning towards classical\\nbenchmarks.\",\n",
      "    \"authors\": \"Alexander Zlokapa, Alex Mott, Joshua Job, Jean-Roch Vlimant, Daniel Lidar, Maria Spiropulu\",\n",
      "    \"id\": 348884468186520099,\n",
      "    \"journal\": \"bullshit\",\n",
      "    \"title\": \"Quantum adiabatic machine learning with zooming\",\n",
      "    \"year\": \"2019\"\n",
      "  }\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"http://localhost:3000/api/project/list_papers\"\n",
    "headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "data = {\n",
    "    'type': \"saved\", # or toread\n",
    "    # 'type': \"toread\", # or toread\n",
    "    'project_id': 148702791823144807,\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "print(response.text)\n",
    "\n",
    "# add_project(\"robotaics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'abstract': 'Quantum computing allows for the potential of significant '\n",
      "                'advancements in\\n'\n",
      "                'both the speed and the capacity of widely used machine '\n",
      "                'learning techniques.\\n'\n",
      "                'Here we employ quantum algorithms for the Hopfield network, '\n",
      "                'which can be used\\n'\n",
      "                'for pattern recognition, reconstruction, and optimization as '\n",
      "                'a realization of a\\n'\n",
      "                'content-addressable memory system. We show that an '\n",
      "                'exponentially large network\\n'\n",
      "                'can be stored in a polynomial number of quantum bits by '\n",
      "                'encoding the network\\n'\n",
      "                'into the amplitudes of quantum states. By introducing a '\n",
      "                'classical technique for\\n'\n",
      "                'operating the Hopfield network, we can leverage quantum '\n",
      "                'algorithms to obtain a\\n'\n",
      "                'quantum computational complexity that is logarithmic in the '\n",
      "                'dimension of the\\n'\n",
      "                'data. We also present an application of our method as a '\n",
      "                'genetic sequence\\n'\n",
      "                'recognizer.',\n",
      "    'authors': [   'Patrick Rebentrost',\n",
      "                   'Thomas R. Bromley',\n",
      "                   'Christian Weedbrook',\n",
      "                   'Seth Lloyd'],\n",
      "    'citations': 125,\n",
      "    'paper_id': '1710.03599',\n",
      "    'title': 'Quantum Hopfield neural network',\n",
      "    'year': '2017'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_semantic_scholar_info(arxiv_id):\n",
    "    base_url = \"https://api.semanticscholar.org/v1/paper/arXiv:\"\n",
    "    \n",
    "    # Fetch data from Semantic Scholar\n",
    "    response = requests.get(base_url + arxiv_id)\n",
    "    data = response.json()\n",
    "\n",
    "    # Return citation count and impact score\n",
    "    # Note: Semantic Scholar doesn't have a generic \"impact score\", but citations can be a metric of impact.\n",
    "    return len(data.get(\"citations\", []))\n",
    "\n",
    "\n",
    "\n",
    "def get_paper_base_data(paper_id):\n",
    "    base_url = \"http://export.arxiv.org/api/query?\"\n",
    "    query = \"id_list=\" + paper_id\n",
    "    \n",
    "    # Send a GET request to the arXiv API\n",
    "    response = requests.get(base_url + query)\n",
    "    \n",
    "    # Raise an exception if the request was unsuccessful\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Parse the XML response\n",
    "    root = ET.fromstring(response.text)\n",
    "    \n",
    "    # Extract information from XML\n",
    "    ns = {'default': 'http://www.w3.org/2005/Atom'}\n",
    "    entry = root.find('default:entry', ns)\n",
    "    \n",
    "    title = entry.find('default:title', ns).text.strip()\n",
    "    authors = [author.find('default:name', ns).text for author in entry.findall('default:author', ns)]\n",
    "    abstract = entry.find('default:summary', ns).text.strip()\n",
    "    year = entry.find('default:published', ns).text.split('-')[0]\n",
    "    \n",
    "    # Return the extracted information in the desired format\n",
    "    return {\n",
    "        \"paper_id\": paper_id,\n",
    "        \"title\": title,\n",
    "        \"authors\": authors,\n",
    "        \"abstract\": abstract,\n",
    "        \"year\": year,\n",
    "        \"citations\": get_semantic_scholar_info(paper_id)\n",
    "    }\n",
    "\n",
    "# Test\n",
    "paper_id = \"1710.03599\"\n",
    "# paper_id = \"2101.12345\"\n",
    "pprint(get_paper_base_data(paper_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_in_project = {\n",
    "    \"paper_id\": \"1710.03599\",\n",
    "    \"project_id\": \"1234567890\",\n",
    "    \"rating\": 1,\n",
    "    \"annotations\": {},\n",
    "    \"engagement\": {\n",
    "        \"view_count\": 0,\n",
    "        \"view_duration\": 0,\n",
    "    },\n",
    "    \"saved\": True,\n",
    "    \"read\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_project(name):\n",
    "    project = {\n",
    "        \"name\": name,\n",
    "        \"papers\": [],\n",
    "        \"imgUrl\": \"/AI.jpeg\"\n",
    "    }\n",
    "    return projects.add(project) # returns id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_paper_to_project(project_id, paper_id):\n",
    "    project_paper = {\n",
    "        \"project_id\": project_id,\n",
    "        \"paper_id\": paper_id,\n",
    "        \"rating\": 1,\n",
    "        \"annotations\": {},\n",
    "        \"engagement\": {\n",
    "            \"click_count\": 0,\n",
    "            \"view_duration\": 0,\n",
    "        },\n",
    "        \"saved\": False,\n",
    "        \"read\": False\n",
    "    }\n",
    "    id = projPapers.add(project_paper)\n",
    "\n",
    "    old_papers = projects.getById(project_id)[\"papers\"]\n",
    "    old_papers.append(id)\n",
    "\n",
    "    projects.updateById(project_id, {\"papers\": old_papers})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_engagement(metric, value, project_id, paper_id):\n",
    "    db_paper_id = projPapers.getByQuery({\"paper_id\": paper_id, \"project_id\": project_id})[0][\"id\"]\n",
    "    \n",
    "    if metric == \"click\":\n",
    "        upd_engagement = projPapers.getById(db_paper_id)[\"engagement\"]\n",
    "        upd_engagement[\"click_count\"] += 1\n",
    "        projPapers.updateById(db_paper_id, {\"engagement\": upd_engagement})\n",
    "    elif metric == \"view\":\n",
    "        upd_engagement = projPapers.getById(db_paper_id)[\"engagement\"]\n",
    "        upd_engagement[\"view_duration\"] += value\n",
    "        projPapers.updateById(db_paper_id, {\"engagement\": upd_engagement})\n",
    "    elif metric == \"read\":\n",
    "        projPapers.updateById(db_paper_id, {\"read\": value})\n",
    "    elif metric == \"save\":\n",
    "        projPapers.updateById(db_paper_id, {\"saved\": value})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n"
     ]
    }
   ],
   "source": [
    "papers = pysondb.db.getDb(\"data/papers\")\n",
    "projects = pysondb.db.getDb(\"data/projects\")\n",
    "projPapers = pysondb.db.getDb(\"data/project_papers\")\n",
    "\n",
    "papers.deleteAll()\n",
    "projects.deleteAll()\n",
    "projPapers.deleteAll()\n",
    "\n",
    "# testing: this is intital data\n",
    "\n",
    "\n",
    "# add quantum\n",
    "project = {\n",
    "    \"name\": \"Quantum Physics\",\n",
    "    \"papers\": [],\n",
    "    \"imgUrl\": \"/QuantumPhysics.jpeg\"\n",
    "}\n",
    "qn_id = projects.add(project)\n",
    "\n",
    "\n",
    "paper_ids = ['1709.02779',\n",
    " '1611.09347',\n",
    " '1611.09347v2',\n",
    " '1708.09757',\n",
    " '1709.02779',\n",
    " '1707.08561v1',\n",
    " '1708.09757v1',\n",
    " '2208.08068',\n",
    " '1710.03599v1',\n",
    " '1908.04480v2']\n",
    "\n",
    "# proj_id = add_project(\"Sample Project\")\n",
    "\n",
    "for paper_id in paper_ids:\n",
    "    papers.add(get_paper_base_data(paper_id))\n",
    "    add_paper_to_project(qn_id, paper_id)\n",
    "\n",
    "    \n",
    "\n",
    "update_engagement(\"click\", 1, qn_id, paper_id)\n",
    "update_engagement(\"view\", 15, qn_id, paper_id)\n",
    "update_engagement(\"view\", 15, qn_id, paper_id)\n",
    "update_engagement(\"read\", True, qn_id, paper_id)\n",
    "update_engagement(\"save\", True, qn_id, paper_id)\n",
    "update_engagement(\"save\", True, qn_id, paper_ids[0])\n",
    "update_engagement(\"save\", True, qn_id, paper_ids[2])\n",
    "update_engagement(\"save\", True, qn_id, paper_ids[3])\n",
    "update_engagement(\"save\", True, qn_id, paper_ids[4])\n",
    "update_engagement(\"read\", True, qn_id, paper_ids[4])\n",
    "update_engagement(\"read\", True, qn_id, paper_ids[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'project_id': 148702791823144807,\n",
       "  'paper_id': '1709.02779',\n",
       "  'rating': 1,\n",
       "  'annotations': {},\n",
       "  'engagement': {'click_count': 0, 'view_duration': 0},\n",
       "  'saved': True,\n",
       "  'read': True,\n",
       "  'id': 178494889177972764},\n",
       " {'project_id': 148702791823144807,\n",
       "  'paper_id': '1611.09347',\n",
       "  'rating': 1,\n",
       "  'annotations': {},\n",
       "  'engagement': {'click_count': 0, 'view_duration': 0},\n",
       "  'saved': False,\n",
       "  'read': False,\n",
       "  'id': 239451734285630063},\n",
       " {'project_id': 148702791823144807,\n",
       "  'paper_id': '1611.09347v2',\n",
       "  'rating': 1,\n",
       "  'annotations': {},\n",
       "  'engagement': {'click_count': 0, 'view_duration': 0},\n",
       "  'saved': True,\n",
       "  'read': True,\n",
       "  'id': 754822796031261480},\n",
       " {'project_id': 148702791823144807,\n",
       "  'paper_id': '1708.09757',\n",
       "  'rating': 1,\n",
       "  'annotations': {},\n",
       "  'engagement': {'click_count': 0, 'view_duration': 0},\n",
       "  'saved': True,\n",
       "  'read': False,\n",
       "  'id': 207245952752736323},\n",
       " {'project_id': 148702791823144807,\n",
       "  'paper_id': '1709.02779',\n",
       "  'rating': 1,\n",
       "  'annotations': {},\n",
       "  'engagement': {'click_count': 0, 'view_duration': 0},\n",
       "  'saved': False,\n",
       "  'read': False,\n",
       "  'id': 321261517891845552},\n",
       " {'project_id': 148702791823144807,\n",
       "  'paper_id': '1707.08561v1',\n",
       "  'rating': 1,\n",
       "  'annotations': {},\n",
       "  'engagement': {'click_count': 0, 'view_duration': 0},\n",
       "  'saved': False,\n",
       "  'read': False,\n",
       "  'id': 221762369844121235},\n",
       " {'project_id': 148702791823144807,\n",
       "  'paper_id': '1708.09757v1',\n",
       "  'rating': 1,\n",
       "  'annotations': {},\n",
       "  'engagement': {'click_count': 0, 'view_duration': 0},\n",
       "  'saved': False,\n",
       "  'read': False,\n",
       "  'id': 301992180675760610},\n",
       " {'project_id': 148702791823144807,\n",
       "  'paper_id': '2208.08068',\n",
       "  'rating': 1,\n",
       "  'annotations': {},\n",
       "  'engagement': {'click_count': 0, 'view_duration': 0},\n",
       "  'saved': False,\n",
       "  'read': False,\n",
       "  'id': 128389792724135020},\n",
       " {'project_id': 148702791823144807,\n",
       "  'paper_id': '1710.03599v1',\n",
       "  'rating': 1,\n",
       "  'annotations': {},\n",
       "  'engagement': {'click_count': 0, 'view_duration': 0},\n",
       "  'saved': False,\n",
       "  'read': False,\n",
       "  'id': 165067520792241930},\n",
       " {'project_id': 148702791823144807,\n",
       "  'paper_id': '1908.04480v2',\n",
       "  'rating': 1,\n",
       "  'annotations': {},\n",
       "  'engagement': {'click_count': 1, 'view_duration': 30},\n",
       "  'saved': True,\n",
       "  'read': True,\n",
       "  'id': 236755119090511479}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projPapers.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'title': 'Opportunities and challenges for quantum-assisted machine learning in\\n  near-term quantum computers',\n",
       "  'authors': 'Alejandro Perdomo-Ortiz, Marcello Benedetti, John Realpe-GÃ³mez, Rupak Biswas',\n",
       "  'abstract': 'With quantum computing technologies nearing the era of commercialization and\\nquantum supremacy, machine learning (ML) appears as one of the promising\\n\"killer\" applications. Despite significant effort, there has been a disconnect\\nbetween most quantum ML proposals, the needs of ML practitioners, and the\\ncapabilities of near-term quantum devices to demonstrate quantum enhancement in\\nthe near future. In this contribution to the focus collection on \"What would\\nyou do with 1000 qubits?\", we provide concrete examples of intractable ML tasks\\nthat could be enhanced with near-term devices. We argue that to reach this\\ntarget, the focus should be on areas where ML researchers are struggling, such\\nas generative models in unsupervised and semi-supervised learning, instead of\\nthe popular and more tractable supervised learning techniques. We also\\nhighlight the case of classical datasets with potential quantum-like\\nstatistical correlations where quantum models could be more suitable. We focus\\non hybrid quantum-classical approaches and illustrate some of the key\\nchallenges we foresee for near-term implementations. Finally, we introduce the\\nquantum-assisted Helmholtz machine (QAHM), an attempt to use near-term quantum\\ndevices to tackle high-dimensional datasets of continuous variables. Instead of\\nusing quantum computers to assist deep learning, as previous approaches do, the\\nQAHM uses deep learning to extract a low-dimensional binary representation of\\ndata, suitable for relatively small quantum processors which can assist the\\ntraining of an unsupervised generative model. Although we illustrate this\\nconcept on a quantum annealer, other quantum platforms could benefit as well\\nfrom this hybrid quantum-classical framework.',\n",
       "  'year': '2017',\n",
       "  'id': 884179599198170424,\n",
       "  'journal': 'bullshit'}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request = {\n",
    "    # 'type': \"saved\", # or toread\n",
    "    'type': \"toread\", # or toread\n",
    "    'project_id': 148702791823144807,\n",
    "}\n",
    "\n",
    "def list_papers():\n",
    "    proj_papers = projPapers.getByQuery({\"project_id\": request[\"project_id\"]})\n",
    "\n",
    "    if request[\"type\"] == \"saved\":\n",
    "        proj_papers = list(filter(lambda x: x[\"saved\"] == True & x[\"read\"] == True, proj_papers))\n",
    "    elif request[\"type\"] == \"toread\":\n",
    "        new = []\n",
    "        for paper in proj_papers:\n",
    "            if paper[\"saved\"] == True and paper[\"read\"] == False:\n",
    "                new.append(paper)\n",
    "        proj_papers = new\n",
    "\n",
    "\n",
    "    # reformat and get paper data\n",
    "    output = []\n",
    "\n",
    "    for paper in proj_papers:\n",
    "        paper_data = papers.getByQuery({\"paper_id\": paper[\"paper_id\"]})[0]\n",
    "        \n",
    "        del paper_data[\"paper_id\"]\n",
    "        del paper_data[\"citations\"]\n",
    "        paper_data[\"journal\"] = \"bullshit\"\n",
    "        paper_data[\"authors\"] = ', '.join(paper_data[\"authors\"])\n",
    "\n",
    "        print(paper['read'], paper['saved'])\n",
    "\n",
    "        output.append(paper_data)\n",
    "\n",
    "\n",
    "\n",
    "    return output\n",
    "\n",
    "list_papers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
